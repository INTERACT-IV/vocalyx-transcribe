# =====================================================================
# Vocalyx Transcribe - Configuration File
# =====================================================================

[CORE]
# Nom unique de cette instance de worker
instance_name = worker-01

[API]
# URL de vocalyx-api pour communiquer
# En local: http://localhost:8000
# En Docker: http://vocalyx-api:8000
url = http://localhost:8000

# Timeout des requêtes HTTP (en secondes)
timeout = 60

[CELERY]
# Configuration Celery (DOIT correspondre à vocalyx-api)
# En Docker: utiliser le nom de service (redis)
# En local: utiliser localhost ou l'IP
broker_url = redis://redis:6379/0
result_backend = redis://redis:6379/0

[REDIS_TRANSCRIPTION]
# DB Redis dédiée pour les opérations de transcription (isolation des données)
# Utilise DB 2 par défaut pour isoler des opérations Celery (DB 0)
# Format: redis://host:port/db_number
# En Docker: utiliser le nom de service (redis)
# En local: utiliser localhost ou l'IP
url = redis://redis:6379/2

# Compression des données JSON (réduit la mémoire et le réseau)
# true: Compresse avec gzip (économise ~60-70% de mémoire)
# false: Stocke en JSON brut (plus rapide mais plus de mémoire)
compress_data = true

# TTL par défaut pour les segments (en secondes)
# Les données expirent automatiquement après ce délai
default_ttl = 3600

[WHISPER]
# Modèle Whisper à utiliser
# Options: tiny, base, small, medium, large-v2, large-v3
# Recommandé: small (bon équilibre vitesse/qualité)
model = /home/shinohk/code/vocalyx-all/shared/models/openai-whisper-small

# Device de calcul
# Options: cpu, cuda (GPU NVIDIA), auto
device = cpu

# Type de calcul
# Options: int8, int8_float16, float16, float32
# int8: Le plus rapide (CPU uniquement)
# float16: Bon équilibre (GPU)
compute_type = int8

# Nombre de threads CPU pour l'inférence
# Recommandé: nombre de cœurs CPU - 2
cpu_threads = 6

# Langue par défaut (forcer la langue accélère la transcription)
# Options: fr, en, es, de, it, pt, nl, etc.
# Laisser vide pour détection automatique
language = fr

[PERFORMANCE]
# Nombre de workers Celery (concurrence)
# Celery gère la concurrence, ne pas confondre avec l'ancien max_workers
# Recommandé: entre 1 et 4 selon votre CPU/GPU
max_workers = 2

# Longueur des segments audio en millisecondes (BASE)
# ⚙️ DÉCOUPAGE ADAPTATIF: La taille sera automatiquement ajustée selon le CPU:
#   - CPU faible (< 4 cores): max 25s (segments plus courts = moins de mémoire)
#   - CPU moyen (4-8 cores): max 35s (équilibre)
#   - CPU puissant (> 8 cores): 45s (segments plus longs = meilleure parallélisation)
# Le nombre de cores est détecté automatiquement au démarrage
segment_length_ms = 45000

# Activer VAD (Voice Activity Detection)
# true: Ignore les silences = plus rapide
vad_enabled = true

# Beam size pour le décodage (qualité vs vitesse)
# 1 = greedy search (plus rapide, recommandé pour CPU)
# 5 = meilleure qualité mais plus lent (recommandé pour GPU)
# Optimisé pour CPU: 1
beam_size = 1

# Best of pour le décodage (nombre de recherches parallèles)
# 1 = une seule recherche (plus rapide, recommandé pour CPU)
# 5 = meilleure qualité mais plus lent
# Optimisé pour CPU: 1
best_of = 1

# Temperature pour le sampling
# 0.0 = déterministe (recommandé)
temperature = 0.0

[PATHS]
# Répertoire partagé pour les uploads (DOIT être identique à vocalyx-api)
upload_dir = /home/shinohk/code/vocalyx-all/shared/uploads

[VAD]
# VAD (Voice Activity Detection) - Paramètres pour faster-whisper 1.1.0+
# Optimisé pour CPU avec VAD intégré de faster-whisper (plus rapide que pydub)

# Seuil de probabilité de parole (0.0-1.0)
# Plus élevé = plus strict (moins de faux positifs)
# Optimisé CPU: 0.5 (équilibre vitesse/qualité)
threshold = 0.5

# Durée minimum de parole pour être considérée (en ms)
# Optimisé CPU: 250ms (balance vitesse/détection)
min_speech_duration_ms = 250

# Durée minimum de silence entre segments (en ms)
# Optimisé CPU: 500ms (plus court = plus de segments mais plus rapide)
min_silence_duration_ms = 500

# Padding ajouté autour des segments de parole (en ms)
# Optimisé CPU: 400ms (bon compromis)
speech_pad_ms = 400

[LOGGING]
# Niveau de log: DEBUG, INFO, WARNING, ERROR, CRITICAL
level = INFO

# Activer les logs dans un fichier
file_enabled = true

# Chemin du fichier de log
file_path = /home/shinohk/code/vocalyx-all/shared/logs/vocalyx-transcribe.log

# Activer les couleurs dans la console
colored = true

[DIARIZATION]
# Configuration de la diarisation des locuteurs

# Activer la diarisation
# true: La diarisation sera disponible (chargée à la demande)
# false: La diarisation sera désactivée (économise la mémoire)
enabled = false

# Type de diarisation
# stereo: Séparation stéréo directe (très rapide, aucun modèle ML, recommandé si fichiers stéréo avec 1 canal/speaker)
# pyannote: Diarisation ML avec pyannote.audio (plus lourd mais plus flexible, supporte mono/stéréo mixtes)
# RECOMMANDÉ: Utiliser 'stereo' pour votre cas d'usage (fichiers stéréo dédiés)
type = stereo

# Modèle de diarisation HuggingFace
# Options: pyannote/speaker-diarization-3.1, pyannote/speaker-diarization-community-1
model = pyannote/speaker-diarization-3.1

# Chemin local vers le modèle (mode offline)
# Si le modèle est téléchargé localement, indiquer le chemin complet
# Sinon, laisser vide pour télécharger depuis HuggingFace
model_path = /app/models/transcribe/pyannote-speaker-diarization

# Token HuggingFace (requis pour les modèles gated)
# Laissez vide si vous utilisez un modèle local ou public
hf_token = 

# OPTIMISATIONS DE PERFORMANCE

# Nombre minimum de locuteurs (vide = auto-détection)
# Indiquer un nombre pour forcer un minimum (ex: 2 pour garantir au moins 2 locuteurs)
# Améliore la précision si le nombre de locuteurs est connu
min_speakers = 1

# Nombre maximum de locuteurs (vide = auto-détection)
# Limiter le nombre maximum permet d'accélérer le traitement
# Recommandé: 2-4 pour des entretiens, 5-10 pour des réunions
max_speakers = 3

# Traitement par chunks pour fichiers longs (en secondes)
# 0 = désactivé (traite le fichier entier)
# 300 = traite par chunks de 5 minutes (recommandé pour réduire CPU)
# 600 = traite par chunks de 10 minutes (recommandé pour fichiers > 10 min)
# AVANTAGES: Réduit l'utilisation mémoire et accélère le traitement
# RÉDUCTION CPU: Plus petits chunks = moins de charge CPU par chunk
chunk_duration_s = 300

# Chevauchement entre chunks (en secondes)
# Permet de fusionner correctement les segments entre chunks
# Recommandé: 5-10 secondes selon la qualité audio
# RÉDUCTION CPU: Réduire à 3-5 secondes pour moins de charge
chunk_overlap_s = 5

# OPTIMISATIONS CPU

# Nombre de threads PyTorch pour la diarization (CPU uniquement)
# 0 = utiliser tous les cores disponibles (par défaut)
# 1-4 = limiter le nombre de threads (réduit la charge CPU)
# RECOMMANDÉ pour réduire CPU: 2-4 threads selon votre configuration
# Exemple: Si vous avez 8 cores, limiter à 4 threads laisse de la marge
num_threads = 6

# Réduire la résolution audio pour traitement plus rapide
# true = downsample l'audio à 8kHz avant traitement (plus rapide, moins précis)
# false = utiliser la résolution originale (plus précis, plus lent)
# RÉDUCTION CPU: Activer reduce_resolution peut réduire de 30-50% l'utilisation CPU
reduce_resolution = false

# Désactiver certaines optimisations coûteuses
# true = mode économique (moins de CPU, légèrement moins précis)
# false = mode complet (plus de CPU, meilleure précision)
# RÉDUCTION CPU: Activer fast_mode peut réduire de 20-40% l'utilisation CPU
fast_mode = false

# Seuil de segmentation (0.0-1.0)
# Plus élevé = plus strict dans la détection des changements de locuteurs
# 0.5 = équilibre (recommandé)
# 0.7+ = plus précis mais plus lent
segmentation_threshold = 0.5

# Seuil de clustering (0.0-1.0)
# Contrôle la similarité requise pour regrouper des segments du même locuteur
# 0.7 = équilibre (recommandé)
# 0.5-0.6 = plus tolérant (peut fusionner des locuteurs différents)
# 0.8+ = plus strict (peut séparer un même locuteur)
clustering_threshold = 0.7

# Utiliser GPU si disponible
# true: Utilise automatiquement le GPU si disponible (beaucoup plus rapide)
# false: Force l'utilisation du CPU
# NOTE: Non utilisé pour type=stereo (pas de GPU nécessaire)
use_gpu_if_available = false

# PARAMÈTRES POUR DIARISATION STÉRÉO (type=stereo uniquement)
# Seuil de silence pour la détection de voix (en dB)
# Plus élevé = plus strict (détecte moins de parole)
# Recommandé: -40 dB (équilibre)
stereo_silence_thresh = -40

# Durée minimale de parole pour être considérée (en ms)
# Recommandé: 250ms (balance vitesse/détection)
stereo_min_speech_ms = 250

[SECURITY]
# Clé secrète pour la communication avec l'API (DOIT être identique à vocalyx-api)
# ⚠️ CHANGER CETTE VALEUR EN PRODUCTION
internal_api_key = SuperSecretCode123