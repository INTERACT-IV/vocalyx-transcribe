"""
vocalyx-transcribe/transcribe/audio_utils.py
Utilitaires pour le traitement audio (adapt√© pour l'architecture microservices)
"""

import logging
from pathlib import Path
from typing import List, Tuple, Optional, Dict

import soundfile as sf
from pydub import AudioSegment
from pydub.effects import normalize
from pydub.silence import detect_nonsilent

logger = logging.getLogger("vocalyx")

def sanitize_filename(filename: str) -> str:
    """
    Nettoie le nom de fichier pour √©viter les injections.
    
    Args:
        filename: Nom de fichier √† nettoyer
        
    Returns:
        str: Nom de fichier s√©curis√©
    """
    return "".join(c for c in filename if c.isalnum() or c in "._-")

def get_audio_duration(file_path: Path) -> float:
    """
    Obtient la dur√©e r√©elle de l'audio en secondes.
    Utilise soundfile pour une mesure pr√©cise.
    
    Args:
        file_path: Chemin vers le fichier audio
        
    Returns:
        float: Dur√©e en secondes
    """
    try:
        info = sf.info(str(file_path))
        duration = round(info.duration, 2)
        logger.debug(f"Audio duration: {duration}s (via soundfile)")
        return duration
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Could not get duration with soundfile: {e}")
        # Fallback avec pydub
        try:
            audio = AudioSegment.from_file(str(file_path))
            duration = round(len(audio) / 1000.0, 2)
            logger.debug(f"Audio duration: {duration}s (via pydub)")
            return duration
        except Exception as e2:
            logger.error(f"‚ùå Could not get duration: {e2}")
            return 0.0

def preprocess_audio(audio_path: Path, preserve_stereo_for_diarization: bool = True) -> Dict[str, Path]:
    """
    Pr√©-traite l'audio pour am√©liorer la qualit√© de transcription.
    - Normalisation du volume
    - Conversion en mono 16kHz pour Whisper
    - Pr√©servation du st√©r√©o pour diarisation (si st√©r√©o d√©tect√©)
    
    Args:
        audio_path: Chemin vers le fichier audio original
        preserve_stereo_for_diarization: Si True, pr√©serve une version st√©r√©o pour diarisation
        
    Returns:
        Dict avec les cl√©s:
        - 'mono': Chemin vers la version mono 16kHz (pour Whisper)
        - 'stereo': Chemin vers la version st√©r√©o pr√©serv√©e (None si mono ou si preserve_stereo_for_diarization=False)
        - 'is_stereo': Boolean indiquant si l'audio original √©tait st√©r√©o
    """
    try:
        logger.debug(f"Preprocessing audio: {audio_path.name}")
        audio = AudioSegment.from_file(str(audio_path))
        
        # D√©tecter si l'audio est st√©r√©o
        is_stereo = audio.channels == 2
        logger.info(f"üîç Audio format detected: {'STEREO' if is_stereo else 'MONO'} ({audio.channels} channel(s))")
        
        # Normalisation du volume
        audio = normalize(audio)
        
        # Version mono pour Whisper (toujours cr√©√©e)
        audio_mono = audio.set_channels(1).set_frame_rate(16000)
        mono_path = audio_path.parent / f"{audio_path.stem}_processed_mono.wav"
        audio_mono.export(str(mono_path), format="wav")
        
        result = {
            'mono': mono_path,
            'stereo': None,
            'is_stereo': is_stereo
        }
        
        # Version st√©r√©o pour diarisation (si st√©r√©o d√©tect√© et pr√©servation demand√©e)
        if is_stereo and preserve_stereo_for_diarization:
            # Pr√©server le st√©r√©o avec normalisation mais sans conversion de sample rate
            audio_stereo = audio.set_frame_rate(16000)  # 16kHz mais st√©r√©o pr√©serv√©
            stereo_path = audio_path.parent / f"{audio_path.stem}_processed_stereo.wav"
            audio_stereo.export(str(stereo_path), format="wav")
            result['stereo'] = stereo_path
            logger.info(f"‚úÖ Preserved STEREO version for diarization: {stereo_path.name}")
            logger.info(f"   üí° STEREO audio: one channel per speaker (optimized for diarization)")
        else:
            if is_stereo and not preserve_stereo_for_diarization:
                logger.info(f"‚ÑπÔ∏è STEREO detected but preservation disabled")
            else:
                logger.info(f"‚ÑπÔ∏è MONO audio: using mono version for both transcription and diarization")
        
        logger.info(f"‚úÖ Audio preprocessed: {mono_path.name}")
        return result
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Preprocessing failed, using original: {e}")
        # Fallback : retourner l'original comme mono
        return {
            'mono': audio_path,
            'stereo': None,
            'is_stereo': False
        }

def detect_speech_segments(
    audio_path: Path,
    min_silence_len: int = 500,
    silence_thresh: int = -40
) -> List[Tuple[int, int]]:
    """
    D√©tecte les segments de parole (Voice Activity Detection).
    
    Args:
        audio_path: Chemin vers le fichier audio
        min_silence_len: Dur√©e minimum de silence en ms (default: 500)
        silence_thresh: Seuil de silence en dB (default: -40)
        
    Returns:
        List[Tuple[int, int]]: Liste de (start_ms, end_ms) des segments avec de la parole
    """
    try:
        audio = AudioSegment.from_file(str(audio_path))
        
        speech_segments = detect_nonsilent(
            audio,
            min_silence_len=min_silence_len,
            silence_thresh=silence_thresh
        )
        
        if not speech_segments:
            # Si aucun segment d√©tect√©, retourner l'audio complet
            return [(0, len(audio))]
        
        logger.info(f"üé§ VAD: Detected {len(speech_segments)} speech segments")
        return speech_segments
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è VAD failed, using full audio: {e}")
        audio = AudioSegment.from_file(str(audio_path))
        return [(0, len(audio))]

def split_audio_intelligent(
    file_path: Path,
    use_vad: bool = True,
    segment_length_ms: Optional[int] = None,
    vad_min_silence_len: int = 500,
    vad_silence_thresh: int = -40,
    force_split_for_distribution: bool = False
) -> List[Path]:
    """
    D√©coupe l'audio de mani√®re intelligente avec taille adaptative.
    Optimis√© Phase 3 : R√©duction de la consommation m√©moire.
    
    Strat√©gies :
    - Audio court (< 60s) : pas de d√©coupe (sauf si force_split_for_distribution=True)
    - Audio avec VAD : D√©coupe temporelle simple (faster-whisper g√®re le VAD int√©gr√©)
    - Audio long sans VAD : d√©coupe par dur√©e fixe (adaptative selon CPU)
    
    Args:
        file_path: Chemin vers le fichier audio
        use_vad: Utiliser la d√©tection de voix (default: True)
        segment_length_ms: Longueur des segments en ms (default: None = 45000 si non fourni)
        vad_min_silence_len: VAD - Dur√©e min de silence en ms (non utilis√© si use_vad=True, faster-whisper le g√®re)
        vad_silence_thresh: VAD - Seuil de silence en dB (non utilis√© si use_vad=True, faster-whisper le g√®re)
        force_split_for_distribution: Si True, force la d√©coupe m√™me pour les audios courts (pour distribution)
        
    Returns:
        List[Path]: Liste des chemins vers les segments audio
    """
    segment_paths = []
    
    # Utiliser valeur par d√©faut si non fournie
    if segment_length_ms is None:
        segment_length_ms = 45000  # Valeur par d√©faut (sera override par config si disponible)
    
    try:
        # Phase 3 - Optimisation : Obtenir la dur√©e sans charger tout l'audio en m√©moire
        try:
            info = sf.info(str(file_path))
            duration_s = info.duration
            duration_ms = int(duration_s * 1000)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Could not get duration with soundfile, using pydub: {e}")
            # Fallback : charger avec pydub seulement pour la dur√©e
            audio = AudioSegment.from_file(str(file_path))
            duration_ms = len(audio)
            duration_s = duration_ms / 1000
            del audio  # Lib√©rer imm√©diatement la m√©moire
        
        # Audio court (< 60s) : pas de d√©coupe (sauf si force_split_for_distribution)
        if duration_s < 60 and not force_split_for_distribution:
            logger.info(f"üìä Audio court ({duration_s:.1f}s), pas de d√©coupe")
            return [file_path]
        
        # Si force_split_for_distribution, utiliser une taille de segment plus petite pour les audios courts
        if force_split_for_distribution and duration_s < 60:
            # Pour les audios courts en mode distribu√©, utiliser des segments de 20-25s
            # Cela permet de mieux distribuer m√™me les audios courts qui g√©n√®rent beaucoup de segments Whisper
            adaptive_segment_length_ms = min(segment_length_ms, int(duration_s * 1000 / 2))  # Au moins 2 segments
            adaptive_segment_length_ms = max(adaptive_segment_length_ms, 20000)  # Minimum 20s
            logger.info(f"üìä Audio court ({duration_s:.1f}s) en mode distribu√©, d√©coupe forc√©e avec segments de {adaptive_segment_length_ms}ms")
            segment_length_ms = adaptive_segment_length_ms
        
        # Phase 3 - Optimisation : Si VAD activ√©, utiliser d√©coupe temporelle simple
        # faster-whisper g√®re d√©j√† le VAD int√©gr√©, pas besoin de detect_speech_segments
        # qui charge tout l'audio en m√©moire
        if use_vad:
            logger.info(f"üéØ Using time-based segmentation with VAD (faster-whisper will handle VAD filtering)")
            # D√©coupe temporelle simple : faster-whisper appliquera le VAD sur chaque segment
            # Cela √©vite de charger tout l'audio deux fois (une fois pour detect_speech_segments, une fois pour export)
            
            # Charger l'audio une seule fois pour la d√©coupe
            audio = AudioSegment.from_file(str(file_path))
            
            # D√©couper par segments temporels (faster-whisper filtrera le silence)
            for i, start_ms in enumerate(range(0, duration_ms, segment_length_ms)):
                end_ms = min(start_ms + segment_length_ms, duration_ms)
                segment = audio[start_ms:end_ms]
                segment_path = file_path.parent / f"{file_path.stem}_vad{i}.wav"
                segment.export(str(segment_path), format="wav")
                segment_paths.append(segment_path)
            
            # Lib√©rer la m√©moire imm√©diatement
            del audio
            
            logger.info(f"üéØ Created {len(segment_paths)} time-based segments (VAD will be applied by faster-whisper)")
            return segment_paths
        
        # D√©coupe classique par dur√©e (sans VAD)
        logger.info(f"üìä Using time-based segmentation ({segment_length_ms}ms chunks)")
        
        # Charger l'audio une seule fois
        audio = AudioSegment.from_file(str(file_path))
        
        if duration_s < 180:  # Audio moyen (< 3 min) : d√©couper en 2
            mid = duration_ms // 2
            for i, (start, end) in enumerate([(0, mid), (mid, duration_ms)]):
                segment = audio[start:end]
                segment_path = file_path.parent / f"{file_path.stem}_seg{i}.wav"
                segment.export(str(segment_path), format="wav")
                segment_paths.append(segment_path)
            logger.info(f"üìä Audio moyen ({duration_s:.1f}s), d√©coupe en 2")
        else:  # Audio long : d√©couper par segments configurables
            for i, start_ms in enumerate(range(0, duration_ms, segment_length_ms)):
                end_ms = min(start_ms + segment_length_ms, duration_ms)
                segment = audio[start_ms:end_ms]
                segment_path = file_path.parent / f"{file_path.stem}_seg{i}.wav"
                segment.export(str(segment_path), format="wav")
                segment_paths.append(segment_path)
            logger.info(f"üìä Audio long ({duration_s:.1f}s), d√©coupe en {len(segment_paths)} segments")
        
        # Lib√©rer la m√©moire imm√©diatement
        del audio
        
        return segment_paths
        
    except Exception as e:
        # En cas d'erreur, nettoyer les segments partiels
        for seg_path in segment_paths:
            seg_path.unlink(missing_ok=True)
        logger.error(f"‚ùå Segmentation error: {e}")
        raise e

def cleanup_segments(segment_paths: List[Path]):
    """
    Nettoie les fichiers de segments temporaires.
    
    Args:
        segment_paths: Liste des chemins vers les segments √† supprimer
    """
    for seg_path in segment_paths:
        try:
            if seg_path.exists():
                seg_path.unlink()
                logger.debug(f"üßπ Deleted segment: {seg_path.name}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Could not delete segment {seg_path.name}: {e}")