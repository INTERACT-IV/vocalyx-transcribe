"""
vocalyx-transcribe/worker.py
Worker Celery pour la transcription audio
"""

import logging
import time
import os
import psutil
import threading
from datetime import datetime
from celery.signals import worker_init
from celery.worker.control import Panel

from celery import Celery
from config import Config
from transcription_service import TranscriptionService
from api_client import VocalyxAPIClient

config = Config()

from logging_config import setup_logging, setup_colored_logging

if config.log_colored:
    logger = setup_colored_logging(
        log_level=config.log_level,
        log_file=config.log_file_path if config.log_file_enabled else None
    )
else:
    logger = setup_logging(
        log_level=config.log_level,
        log_file=config.log_file_path if config.log_file_enabled else None
    )

# --- MODIFICATION 2 : D√©clarer les services comme 'None' ---
_api_client = None
_transcription_service = None

# --- PHASE 3 : Cache de mod√®les Whisper ---
_model_cache = {}
_model_cache_lock = threading.Lock()
_MAX_CACHED_MODELS = 2  # Limiter √† 2 mod√®les en cache pour √©conomiser la m√©moire

# --- AJOUTS : Variables globales pour psutil ---
WORKER_PROCESS = None
WORKER_START_TIME = None

@worker_init.connect
def on_worker_init(**kwargs):
    """Initialise psutil quand le worker d√©marre."""
    global WORKER_PROCESS, WORKER_START_TIME
    try:
        WORKER_PROCESS = psutil.Process(os.getpid())
        WORKER_START_TIME = datetime.now()
        WORKER_PROCESS.cpu_percent(interval=None) # Initialiser la mesure
        logger.info(f"Worker {WORKER_PROCESS.pid} initialis√© pour monitoring psutil.")
    except Exception as e:
        logger.error(f"Erreur lors de l'initialisation de psutil: {e}")
# --- FIN AJOUTS ---


def get_api_client():
    """Charge le client API (une fois par worker)"""
    global _api_client
    if _api_client is None:
        logger.info(f"Initialisation du client API pour ce worker ({config.instance_name})...")
        _api_client = VocalyxAPIClient(config)
    return _api_client

def get_transcription_service(model_name: str = 'small'):
    """
    Charge le service de transcription avec cache par mod√®le (Phase 3 - Optimisation).
    
    Args:
        model_name: Nom du mod√®le Whisper (tiny, base, small, medium, large) ou chemin
        
    Returns:
        TranscriptionService: Service de transcription avec le mod√®le demand√©
    """
    global _model_cache, _transcription_service
    
    # Normaliser le nom du mod√®le
    if not model_name:
        model_name = 'small'
    else:
        model_name = model_name.lower()
        # Si c'est un chemin, extraire le nom du mod√®le
        # Ex: "./models/openai-whisper-small" -> "small"
        if 'openai-whisper-' in model_name:
            model_name = model_name.split('openai-whisper-')[-1].split('/')[-1].split('\\')[-1]
        # Si c'est juste un chemin relatif, utiliser 'small' par d√©faut
        elif model_name.startswith('./') or model_name.startswith('/'):
            # Essayer d'extraire le nom du mod√®le du chemin
            parts = model_name.replace('\\', '/').split('/')
            for part in reversed(parts):
                if part in ['tiny', 'base', 'small', 'medium', 'large']:
                    model_name = part
                    break
            else:
                model_name = 'small'  # Fallback
    
    # Si aucun mod√®le sp√©cifi√©, utiliser l'ancien comportement (r√©trocompatibilit√©)
    if model_name == 'small' and _transcription_service is not None:
        # V√©rifier si le service existant utilise le mod√®le par d√©faut
        if not hasattr(_transcription_service, 'model_name') or _transcription_service.model_name == 'small':
            return _transcription_service
    
    # Utiliser le cache de mod√®les
    with _model_cache_lock:
        # V√©rifier si le mod√®le est d√©j√† en cache
        if model_name in _model_cache:
            logger.info(f"‚úÖ Using cached Whisper model: {model_name}")
            _model_cache[model_name]['last_used'] = time.time()
            return _model_cache[model_name]['service']
        
        # Si le cache est plein, supprimer le moins r√©cemment utilis√© (LRU)
        if len(_model_cache) >= _MAX_CACHED_MODELS:
            oldest_model = min(_model_cache.keys(), 
                             key=lambda k: _model_cache[k]['last_used'])
            logger.info(f"üóëÔ∏è Removing least recently used model from cache: {oldest_model}")
            del _model_cache[oldest_model]
        
        # Charger le nouveau mod√®le
        logger.info(f"üöÄ Loading Whisper model into cache: {model_name} (cache: {len(_model_cache)}/{_MAX_CACHED_MODELS})")
        try:
            service = TranscriptionService(config, model_name=model_name)
            _model_cache[model_name] = {
                'service': service,
                'last_used': time.time()
            }
            logger.info(f"‚úÖ Model {model_name} loaded and cached successfully")
            
            # Si c'est le mod√®le par d√©faut (small), mettre √† jour aussi _transcription_service pour r√©trocompatibilit√©
            if model_name == 'small':
                _transcription_service = service
            
            return service
        except Exception as e:
            logger.error(f"‚ùå Failed to load model {model_name}: {e}", exc_info=True)
            raise

# --- FIN DES MODIFICATIONS GLOBALES ---


# Cr√©er l'application Celery (connexion au m√™me broker que vocalyx-api)
celery_app = Celery(
    'vocalyx-transcribe',
    broker=config.celery_broker_url,
    backend=config.celery_result_backend
)

# ... (votre configuration Celery conf.update reste inchang√©e) ...
celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    worker_prefetch_multiplier=1,
    worker_max_tasks_per_child=10,
    task_acks_late=True,
    task_reject_on_worker_lost=True,
    broker_connection_retry_on_startup=True,
    worker_send_task_events=True,
    task_send_sent_event=True,
    # Configuration du format de logging pour Celery
    worker_log_format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    worker_task_log_format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    worker_log_datefmt='%Y-%m-%d %H:%M:%S',
    # D√©sactiver le warning de s√©curit√© pour les containers Docker (on tourne en root par design)
    worker_disable_rate_limits=False,
    # Ignorer le warning de s√©curit√© root dans les containers Docker
    worker_hijack_root_logger=False,
)


@Panel.register(
    name='get_worker_health',
    alias='health'
)
def get_worker_health_handler(state, **kwargs):
    """
    Handler pour la commande de contr√¥le 'get_worker_health'.
    Ne retourne que les stats psutil (CPU/RAM/Uptime).
    """
    if WORKER_PROCESS is None:
        logger.warning("get_worker_health_handler appel√© avant initialisation de psutil.")
        return {'error': 'Worker not initialized'}
    
    try:
        mem_info = WORKER_PROCESS.memory_info()
        uptime_seconds = (datetime.now() - WORKER_START_TIME).total_seconds()
        
        # Les stats m√©tier (audio trait√©) sont calcul√©es par l'API
        
        health_data = {
            'pid': WORKER_PROCESS.pid,
            'cpu_percent': WORKER_PROCESS.cpu_percent(interval=None),
            'memory_rss_bytes': mem_info.rss,
            'memory_percent': WORKER_PROCESS.memory_percent(),
            'uptime_seconds': uptime_seconds
        }
        
        return health_data
        
    except Exception as e:
        logger.error(f"Erreur dans get_worker_health_handler: {e}", exc_info=True)
        return {'error': str(e)}

@celery_app.task(
    bind=True,
    name='transcribe_audio',
    max_retries=3,
    default_retry_delay=60,
    soft_time_limit=1800,
    time_limit=2100,
    acks_late=True,
    reject_on_worker_lost=True
)
def transcribe_audio_task(self, transcription_id: str):
    """
    T√¢che de transcription ex√©cut√©e par le worker.
    """
    
    logger.info(f"[{transcription_id}] üéØ Task started by worker {config.instance_name}")
    start_time = time.time()
    
    try:
        # Assure que le client API est initialis√©
        api_client = get_api_client()

        # 1. R√©cup√©rer les informations de la transcription depuis l'API
        logger.info(f"[{transcription_id}] üì° Fetching transcription data from API...")
        transcription = api_client.get_transcription(transcription_id)
        
        if not transcription:
            raise ValueError(f"Transcription {transcription_id} not found")
        
        file_path = transcription.get('file_path')
        use_vad = transcription.get('vad_enabled', True)
        use_diarization = transcription.get('diarization_enabled', False)
        whisper_model = transcription.get('whisper_model', 'small')  # R√©cup√©rer le mod√®le choisi
        
        logger.info(f"[{transcription_id}] üìÅ File: {file_path} | VAD: {use_vad} | Diarization: {use_diarization} | Model: {whisper_model}")
        
        # 2. Mettre √† jour le statut √† "processing"
        api_client.update_transcription(transcription_id, {
            "status": "processing",
            "worker_id": config.instance_name
        })
        logger.info(f"[{transcription_id}] ‚öôÔ∏è Status updated to 'processing'")
        
        # 3. Obtenir le service de transcription avec cache de mod√®les (Phase 3 - Optimisation)
        # Le cache r√©utilise les mod√®les d√©j√† charg√©s, √©vitant 5-15s de chargement
        logger.info(f"[{transcription_id}] üé§ Getting transcription service with model: {whisper_model} (cached)")
        transcription_service = get_transcription_service(model_name=whisper_model)
        
        # 4. Ex√©cuter la transcription
        logger.info(f"[{transcription_id}] üé§ Starting transcription with Whisper...")
        
        result = transcription_service.transcribe(
            file_path=file_path,
            use_vad=use_vad,
            use_diarization=use_diarization,
            transcription_id=transcription_id
        )
        
        logger.info(f"[{transcription_id}] ‚úÖ Transcription service completed")
        
        processing_time = round(time.time() - start_time, 2)
        
        logger.info(
            f"[{transcription_id}] ‚úÖ Transcription completed | "
            f"Duration: {result['duration']}s | "
            f"Processing: {processing_time}s | "
            f"Segments: {len(result['segments'])}"
        )
        
        # 4. Mettre √† jour avec les r√©sultats
        logger.info(f"[{transcription_id}] üíæ Saving results to API...")
        import json
        api_client.update_transcription(transcription_id, {
            "status": "done",
            "text": result["text"],
            "segments": json.dumps(result["segments"]),
            "language": result["language"],
            "duration": result["duration"],
            "processing_time": processing_time,
            "segments_count": len(result["segments"])
        })
        
        logger.info(f"[{transcription_id}] üíæ Results saved to API")
        
        return {
            "status": "success",
            "transcription_id": transcription_id,
            "duration": result["duration"],
            "processing_time": processing_time,
            "segments_count": len(result["segments"])
        }
        
    except Exception as e:
        logger.error(f"[{transcription_id}] ‚ùå Error: {e}", exc_info=True)
        
        # Mettre √† jour le statut √† "error"
        try:
            api_client_on_error = get_api_client()
            api_client_on_error.update_transcription(transcription_id, {
                "status": "error",
                "error_message": str(e)
            })
        except Exception as update_error:
            logger.error(f"[{transcription_id}] Failed to update error status: {update_error}")
        
        # Retry si possible
        if self.request.retries < self.max_retries:
            logger.warning(f"[{transcription_id}] ‚è≥ Retrying in {self.default_retry_delay}s...")
            raise self.retry(exc=e)
        
        # Si toutes les tentatives √©chouent
        logger.error(f"[{transcription_id}] ‚õî All retries exhausted")
        return {
            "status": "error",
            "transcription_id": transcription_id,
            "error": str(e)
        }

if __name__ == "__main__":
    # ... (Le reste de votre fichier __main__ est parfait et n'a pas besoin d'√™tre modifi√©) ...
    logger.info(f"üöÄ Starting Celery worker: {config.instance_name}")
    celery_app.worker_main([
        'worker',
        f'--loglevel={config.log_level.lower()}',
        f'--concurrency={config.max_workers}',
        f'--hostname={config.instance_name}@%h'
    ])