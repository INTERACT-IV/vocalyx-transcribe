"""
vocalyx-transcribe/worker.py
Worker Celery pour la transcription audio
"""

import logging
import time
import os
import psutil
import threading
import json
import redis
import gzip
import base64
from pathlib import Path
from datetime import datetime
from celery.signals import worker_init
from celery.worker.control import Panel

from celery import Celery
from config import Config
from transcription_service import TranscriptionService  # Compatibilit√©
from api_client import VocalyxAPIClient  # Compatibilit√©
from infrastructure.api.api_client import VocalyxAPIClient as VocalyxAPIClientRefactored
from application.services.transcription_worker_service import TranscriptionWorkerService
from audio_utils import split_audio_intelligent, preprocess_audio, get_audio_duration

config = Config()

from logging_config import setup_logging, setup_colored_logging

if config.log_colored:
    logger = setup_colored_logging(
        log_level=config.log_level,
        log_file=config.log_file_path if config.log_file_enabled else None
    )
else:
    logger = setup_logging(
        log_level=config.log_level,
        log_file=config.log_file_path if config.log_file_enabled else None
    )

# --- MODIFICATION 2 : D√©clarer les services comme 'None' ---
_api_client = None
_transcription_service = None
_redis_client = None

def get_redis_client():
    """Obtient un client Redis pour stocker les r√©sultats des segments"""
    global _redis_client
    if _redis_client is None:
        # Utiliser la DB Redis d√©di√©e pour les transcriptions (isolation des donn√©es)
        redis_url = getattr(config, 'redis_transcription_url', None)
        if not redis_url:
            # Fallback : utiliser DB 2 de la m√™me instance
            base_url = config.celery_broker_url.rsplit('/', 1)[0]  # Enlever /0
            redis_url = f"{base_url}/2"
        
        logger.info(f"üîå Initializing Redis transcription client: {redis_url}")
        _redis_client = redis.from_url(redis_url, decode_responses=True)
        
        # Test de connexion
        try:
            _redis_client.ping()
            logger.info(f"‚úÖ Redis transcription client connected successfully: {redis_url}")
        except Exception as e:
            logger.error(f"‚ùå Failed to connect to Redis transcription: {redis_url} - {e}")
            raise
    
    return _redis_client

def _compress_json(data: dict) -> str:
    """Compresse un dictionnaire JSON pour √©conomiser la m√©moire Redis"""
    if not getattr(config, 'redis_transcription_compress', True):
        return json.dumps(data)
    
    json_str = json.dumps(data)
    compressed = gzip.compress(json_str.encode('utf-8'), compresslevel=6)
    # Encoder en base64 pour stockage Redis (string)
    return base64.b64encode(compressed).decode('utf-8')

def _decompress_json(compressed_str: str) -> dict:
    """D√©compresse une cha√Æne JSON compress√©e"""
    if not getattr(config, 'redis_transcription_compress', True):
        return json.loads(compressed_str)
    
    try:
        # D√©coder depuis base64
        compressed = base64.b64decode(compressed_str.encode('utf-8'))
        # D√©compresser
        json_str = gzip.decompress(compressed).decode('utf-8')
        return json.loads(json_str)
    except Exception as e:
        # Si la d√©compression √©choue, essayer de parser comme JSON normal (r√©trocompatibilit√©)
        logger.warning(f"‚ö†Ô∏è Failed to decompress, trying as plain JSON: {e}")
        return json.loads(compressed_str)

# --- PHASE 3 : Cache de mod√®les Whisper ---
_model_cache = {}
_model_cache_lock = threading.Lock()
_MAX_CACHED_MODELS = 2  # Nombre maximum de mod√®les en cache (LRU)

# --- AJOUTS : Variables globales pour psutil ---
WORKER_PROCESS = None
WORKER_START_TIME = None

@worker_init.connect
def on_worker_init(**kwargs):
    """Initialise psutil quand le worker d√©marre."""
    global WORKER_PROCESS, WORKER_START_TIME
    try:
        WORKER_PROCESS = psutil.Process(os.getpid())
        WORKER_START_TIME = datetime.now()
        WORKER_PROCESS.cpu_percent(interval=None) # Initialiser la mesure
        logger.info(f"Worker {WORKER_PROCESS.pid} initialis√© pour monitoring psutil.")
    except Exception as e:
        logger.error(f"Erreur lors de l'initialisation de psutil: {e}")
# --- FIN AJOUTS ---


def get_api_client():
    """Charge le client API (une fois par worker) - Version refactoris√©e"""
    global _api_client
    if _api_client is None:
        logger.info(f"Initialisation du client API pour ce worker ({config.instance_name})...")
        _api_client = VocalyxAPIClientRefactored(config)
    return _api_client

def get_worker_service():
    """Charge le service worker (une fois par worker)"""
    api_client = get_api_client()
    return TranscriptionWorkerService(api_client)

def get_transcription_service(model_name: str = 'small'):
    """
    Charge le service de transcription avec cache par mod√®le (Phase 3 - Optimisation).
    
    Args:
        model_name: Nom du mod√®le Whisper (tiny, base, small, medium, large) ou chemin
        
    Returns:
        TranscriptionService: Service de transcription avec le mod√®le demand√©
    """
    global _model_cache, _transcription_service
    
    # Normaliser le nom du mod√®le
    if not model_name:
        model_name = 'small'
    else:
        model_name = model_name.lower()
        # Si c'est un chemin, extraire le nom du mod√®le
        # Ex: "./models/openai-whisper-small" -> "small"
        if 'openai-whisper-' in model_name:
            model_name = model_name.split('openai-whisper-')[-1].split('/')[-1].split('\\')[-1]
        # Si c'est juste un chemin relatif, utiliser 'small' par d√©faut
        elif model_name.startswith('./') or model_name.startswith('/'):
            # Essayer d'extraire le nom du mod√®le du chemin
            parts = model_name.replace('\\', '/').split('/')
            for part in reversed(parts):
                if part in ['tiny', 'base', 'small', 'medium', 'large']:
                    model_name = part
                    break
            else:
                model_name = 'small'  # Fallback
    
    # Si aucun mod√®le sp√©cifi√©, utiliser l'ancien comportement (r√©trocompatibilit√©)
    if model_name == 'small' and _transcription_service is not None:
        # V√©rifier si le service existant utilise le mod√®le par d√©faut
        if not hasattr(_transcription_service, 'model_name') or _transcription_service.model_name == 'small':
            return _transcription_service
    
    # Utiliser le cache de mod√®les
    with _model_cache_lock:
        # V√©rifier si le mod√®le est d√©j√† en cache
        if model_name in _model_cache:
            logger.info(f"‚úÖ Using cached Whisper model: {model_name}")
            _model_cache[model_name]['last_used'] = time.time()
            return _model_cache[model_name]['service']
        
        # Si le cache est plein, supprimer le moins r√©cemment utilis√© (LRU)
        if len(_model_cache) >= _MAX_CACHED_MODELS:
            oldest_model = min(_model_cache.keys(), 
                             key=lambda k: _model_cache[k]['last_used'])
            logger.info(f"üóëÔ∏è Removing least recently used model from cache: {oldest_model}")
            del _model_cache[oldest_model]
        
        # Charger le nouveau mod√®le
        logger.info(f"üöÄ Loading Whisper model into cache: {model_name} (cache: {len(_model_cache)}/{_MAX_CACHED_MODELS})")
        try:
            # Le TranscriptionService charge maintenant TOUS les mod√®les au d√©marrage
            # (Whisper + pyannote) avec des logs d√©taill√©s
            service = TranscriptionService(config, model_name=model_name)
            _model_cache[model_name] = {
                'service': service,
                'last_used': time.time()
            }
            logger.info(f"‚úÖ Model {model_name} loaded and cached successfully")
            
            # Note: Le message "WORKER PR√äT" est maintenant affich√© dans @worker_init
            # apr√®s le chargement de tous les mod√®les
            
            # Si c'est le mod√®le par d√©faut (small), mettre √† jour aussi _transcription_service pour r√©trocompatibilit√©
            if model_name == 'small':
                _transcription_service = service
            
            return service
        except Exception as e:
            logger.error(f"‚ùå Failed to load model {model_name}: {e}", exc_info=True)
            raise

# --- FIN DES MODIFICATIONS GLOBALES ---


# Cr√©er l'application Celery (connexion au m√™me broker que vocalyx-api)
celery_app = Celery(
    'vocalyx-transcribe',
    broker=config.celery_broker_url,
    backend=config.celery_result_backend
)

# ... (votre configuration Celery conf.update reste inchang√©e) ...
celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
    worker_prefetch_multiplier=1,
    worker_max_tasks_per_child=10,
    task_acks_late=True,
    task_reject_on_worker_lost=True,
    broker_connection_retry_on_startup=True,
    worker_send_task_events=True,
    task_send_sent_event=True,
    # Configuration du format de logging pour Celery
    worker_log_format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    worker_task_log_format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    worker_log_datefmt='%Y-%m-%d %H:%M:%S',
    # D√©sactiver le warning de s√©curit√© pour les containers Docker (on tourne en root par design)
    worker_disable_rate_limits=False,
    # Ignorer le warning de s√©curit√© root dans les containers Docker
    worker_hijack_root_logger=False,
)


@Panel.register(
    name='get_worker_health',
    alias='health'
)
def get_worker_health_handler(state, **kwargs):
    """
    Handler pour la commande de contr√¥le 'get_worker_health'.
    Ne retourne que les stats psutil (CPU/RAM/Uptime).
    """
    if WORKER_PROCESS is None:
        logger.warning("get_worker_health_handler appel√© avant initialisation de psutil.")
        return {'error': 'Worker not initialized'}
    
    try:
        mem_info = WORKER_PROCESS.memory_info()
        uptime_seconds = (datetime.now() - WORKER_START_TIME).total_seconds()
        
        # Les stats m√©tier (audio trait√©) sont calcul√©es par l'API
        
        health_data = {
            'pid': WORKER_PROCESS.pid,
            'cpu_percent': WORKER_PROCESS.cpu_percent(interval=None),
            'memory_rss_bytes': mem_info.rss,
            'memory_percent': WORKER_PROCESS.memory_percent(),
            'uptime_seconds': uptime_seconds
        }
        
        return health_data
        
    except Exception as e:
        logger.error(f"Erreur dans get_worker_health_handler: {e}", exc_info=True)
        return {'error': str(e)}

@celery_app.task(
    bind=True,
    name='transcribe_audio',  # M√™me nom que dans l'API pour compatibilit√©
    max_retries=3,
    default_retry_delay=60,
    soft_time_limit=1800,
    time_limit=2100,
    acks_late=True,
    reject_on_worker_lost=True
)
def transcribe_audio_task(self, transcription_id: str, use_distributed: bool = None):
    """
    T√¢che de transcription ex√©cut√©e par le worker.
    
    Si use_distributed=True ou si l'audio d√©passe le seuil, cette t√¢che va
    d√©l√©guer √† orchestrate_distributed_transcription au lieu de traiter directement.
    """
    
    # Assure que le client API est initialis√©
    api_client = get_api_client()
    
    # 1. R√©cup√©rer les informations de la transcription depuis l'API
    logger.info(f"[{transcription_id}] üì° Fetching transcription data from API...")
    transcription = api_client.get_transcription(transcription_id)
    
    if not transcription:
        raise ValueError(f"Transcription {transcription_id} not found")
    
    file_path = transcription.get('file_path')
    
    # V√©rifier si on doit utiliser le mode distribu√©
    if use_distributed is None:
        from pathlib import Path
        try:
            if file_path:
                file_path_obj = Path(file_path)
                if file_path_obj.exists():
                    import soundfile as sf
                    duration = sf.info(str(file_path_obj)).duration
                    # Utiliser le seuil depuis la config (par d√©faut 30s)
                    min_duration = 30  # TODO: R√©cup√©rer depuis config si possible
                    use_distributed = duration > min_duration
                    logger.info(
                        f"[{transcription_id}] üìä DISTRIBUTION DECISION (worker) | "
                        f"Duration: {duration:.1f}s | "
                        f"Threshold: {min_duration}s | "
                        f"Mode: {'DISTRIBUTED' if use_distributed else 'CLASSIC'}"
                    )
        except Exception as e:
            logger.warning(f"[{transcription_id}] ‚ö†Ô∏è Could not determine distribution mode: {e}")
            use_distributed = False
    
    # Si mode distribu√©, d√©l√©guer √† orchestrate_distributed_transcription
    if use_distributed and file_path:
        from pathlib import Path
        file_path_obj = Path(file_path)
        if file_path_obj.exists():
            logger.info(
                f"[{transcription_id}] üöÄ DISTRIBUTED MODE | "
                f"Delegating to orchestrate_distributed_transcription | "
                f"Worker: {config.instance_name}"
            )
            from celery import current_app as celery_current_app
            
            # Envoyer la t√¢che d'orchestration
            orchestrate_task = celery_current_app.send_task(
                'orchestrate_distributed_transcription',
                args=[transcription_id, str(file_path)],
                queue='transcription',
                countdown=1
            )
            
            logger.info(
                f"[{transcription_id}] ‚úÖ DISTRIBUTED MODE | "
                f"Orchestration task enqueued: {orchestrate_task.id}"
            )
            
            return {
                "transcription_id": transcription_id,
                "task_id": self.request.id,
                "orchestration_task_id": orchestrate_task.id,
                "status": "queued_distributed",
                "mode": "distributed"
            }
    
    # MODE CLASSIQUE : Traitement direct
    logger.info(
        f"[{transcription_id}] üéØ CLASSIC MODE STARTED | "
        f"Worker: {config.instance_name} | "
        f"Task ID: {self.request.id} | "
        f"Mode: Single worker processing entire audio (non-distributed)"
    )
    start_time = time.time()
    
    try:
        use_vad = transcription.get('vad_enabled', True)
        use_diarization = transcription.get('diarization_enabled', False)
        whisper_model = transcription.get('whisper_model', 'small')  # R√©cup√©rer le mod√®le choisi
        
        logger.info(f"[{transcription_id}] üìÅ File: {file_path} | VAD: {use_vad} | Diarization: {use_diarization} | Model: {whisper_model}")
        
        # 2. Mettre √† jour le statut √† "processing"
        api_client.update_transcription(transcription_id, {
            "status": "processing",
            "worker_id": config.instance_name
        })
        logger.info(f"[{transcription_id}] ‚öôÔ∏è Status updated to 'processing'")
        
        # 3. Obtenir le service de transcription avec cache de mod√®les (Phase 3 - Optimisation)
        # Le cache r√©utilise les mod√®les d√©j√† charg√©s, √©vitant 5-15s de chargement
        logger.info(f"[{transcription_id}] üé§ Getting transcription service with model: {whisper_model} (cached)")
        transcription_service = get_transcription_service(model_name=whisper_model)
        
        # 4. Ex√©cuter la transcription
        logger.info(f"[{transcription_id}] üé§ Starting transcription with Whisper...")
        
        result = transcription_service.transcribe(
            file_path=file_path,
            use_vad=use_vad,
            use_diarization=use_diarization,
            transcription_id=transcription_id
        )
        
        logger.info(f"[{transcription_id}] ‚úÖ Transcription service completed")
        
        processing_time = round(time.time() - start_time, 2)
        
        logger.info(
            f"[{transcription_id}] ‚úÖ Transcription completed | "
            f"Duration: {result['duration']}s | "
            f"Processing: {processing_time}s | "
            f"Segments: {len(result['segments'])}"
        )
        
        # 4. Mettre √† jour avec les r√©sultats
        logger.info(f"[{transcription_id}] üíæ Saving results to API...")
        import json
        enrichment_requested = transcription.get('enrichment_requested', False)
        
        # Si l'enrichissement est demand√©, mettre le statut √† "transcribed" au lieu de "done"
        # Le statut sera chang√© √† "done" uniquement quand l'enrichissement sera termin√©
        status = "transcribed" if enrichment_requested else "done"
        
        api_client.update_transcription(transcription_id, {
            "status": status,
            "text": result["text"],
            "segments": json.dumps(result["segments"]),
            "language": result["language"],
            "duration": result["duration"],
            "processing_time": processing_time,
            "segments_count": len(result["segments"])
        })
        
        logger.info(f"[{transcription_id}] üíæ Results saved to API (status: {status})")
        
        # 5. Si l'enrichissement est demand√©, d√©clencher la t√¢che d'enrichissement
        if enrichment_requested:
            try:
                logger.info(f"[{transcription_id}] ü§ñ Enrichment requested, triggering enrichment task...")
                # Importer la t√¢che d'enrichissement depuis celery_app
                from celery import current_app as celery_current_app
                enrich_task = celery_current_app.send_task(
                    'enrich_transcription',
                    args=[transcription_id],
                    queue='enrichment',  # Utiliser la queue d'enrichissement
                    countdown=1  # D√©marrer apr√®s 1 seconde
                )
                logger.info(f"[{transcription_id}] ‚úÖ Enrichment task enqueued: {enrich_task.id}")
            except Exception as enrich_error:
                logger.warning(f"[{transcription_id}] ‚ö†Ô∏è Failed to enqueue enrichment task: {enrich_error}")
                # Ne pas √©chouer la transcription si l'enrichissement √©choue √† √™tre enqueu√©e
                # On met simplement le statut d'enrichissement en erreur
                try:
                    api_client.update_transcription(transcription_id, {
                        "enrichment_status": "error",
                        "enrichment_error": f"Failed to enqueue enrichment: {str(enrich_error)}"
                    })
                except:
                    pass
        
        return {
            "status": "success",
            "transcription_id": transcription_id,
            "duration": result["duration"],
            "processing_time": processing_time,
            "segments_count": len(result["segments"]),
            "enrichment_triggered": enrichment_requested
        }
        
    except Exception as e:
        logger.error(f"[{transcription_id}] ‚ùå Error: {e}", exc_info=True)
        
        # Mettre √† jour le statut √† "error"
        try:
            api_client_on_error = get_api_client()
            api_client_on_error.update_transcription(transcription_id, {
                "status": "error",
                "error_message": str(e)
            })
        except Exception as update_error:
            logger.error(f"[{transcription_id}] Failed to update error status: {update_error}")
        
        # Retry si possible
        if self.request.retries < self.max_retries:
            logger.warning(f"[{transcription_id}] ‚è≥ Retrying in {self.default_retry_delay}s...")
            raise self.retry(exc=e)
        
        # Si toutes les tentatives √©chouent
        logger.error(f"[{transcription_id}] ‚õî All retries exhausted")
        return {
            "status": "error",
            "transcription_id": transcription_id,
            "error": str(e)
        }

@celery_app.task(
    bind=True,
    name='orchestrate_distributed_transcription',
    max_retries=2,
    default_retry_delay=30,
    acks_late=True
)
def orchestrate_distributed_transcription_task(self, transcription_id: str, file_path: str):
    """
    Orchestre la transcription distribu√©e : d√©coupe l'audio et cr√©e les t√¢ches de segments.
    
    Args:
        transcription_id: ID de la transcription
        file_path: Chemin vers le fichier audio
    """
    logger.info(
        f"[{transcription_id}] üéº DISTRIBUTED ORCHESTRATION STARTED | "
        f"Worker: {config.instance_name} | "
        f"File: {Path(file_path).name} | "
        f"Task ID: {self.request.id}"
    )
    
    try:
        api_client = get_api_client()
        transcription = api_client.get_transcription(transcription_id)
        
        if not transcription:
            raise ValueError(f"Transcription {transcription_id} not found")
        
        file_path_obj = Path(file_path)
        if not file_path_obj.exists():
            raise FileNotFoundError(f"Audio file not found: {file_path}")
        
        use_vad = transcription.get('vad_enabled', True)
        whisper_model = transcription.get('whisper_model', 'small')
        
        # Mettre √† jour le statut
        api_client.update_transcription(transcription_id, {
            "status": "processing",
            "worker_id": f"{config.instance_name}-orchestrator"
        })
        
        # 1. Pr√©-traiter l'audio
        logger.info(f"[{transcription_id}] üîß DISTRIBUTED ORCHESTRATION | Step 1/4: Preprocessing audio...")
        preprocessed = preprocess_audio(file_path_obj, preserve_stereo_for_diarization=transcription.get('diarization_enabled', False))
        processed_path_mono = preprocessed['mono']
        
        # 2. D√©couper en segments (forcer la d√©coupe car on est en mode distribu√©)
        logger.info(
            f"[{transcription_id}] ‚úÇÔ∏è DISTRIBUTED ORCHESTRATION | Step 2/4: Splitting audio into segments | "
            f"VAD: {use_vad} | Segment length: {config.segment_length_ms}ms | "
            f"Force split: True (distributed mode)"
        )
        segment_paths = split_audio_intelligent(
            processed_path_mono,
            use_vad=use_vad,
            segment_length_ms=config.segment_length_ms,
            force_split_for_distribution=True  # Forcer la d√©coupe en mode distribu√©
        )
        
        num_segments = len(segment_paths)
        logger.info(
            f"[{transcription_id}] ‚úÖ DISTRIBUTED ORCHESTRATION | Step 2/4: Segmentation complete | "
            f"Segments created: {num_segments} | "
            f"Will be distributed across available workers"
        )
        
        if num_segments == 0:
            raise ValueError("No segments created")
        
        # 3. Stocker les m√©tadonn√©es dans Redis
        redis_client = get_redis_client()
        segments_key = f"transcription:{transcription_id}:segments"
        # Timestamp de d√©but pour calculer le temps r√©el √©coul√©
        orchestration_start_time = time.time()
        
        segments_metadata = {
            "transcription_id": transcription_id,
            "total_segments": num_segments,
            "completed_segments": 0,
            "segment_paths": [str(p) for p in segment_paths],
            "use_vad": use_vad,
            "use_diarization": transcription.get('diarization_enabled', False),
            "whisper_model": whisper_model,
            "processed_path_mono": str(processed_path_mono),
            "processed_path_stereo": str(preprocessed.get('stereo')) if preprocessed.get('stereo') else None,
            "is_stereo": preprocessed.get('is_stereo', False),
            "original_duration": get_audio_duration(file_path_obj),
            "orchestration_start_time": orchestration_start_time  # Timestamp de d√©but pour calculer le temps r√©el
        }
        # Stocker avec compression si activ√©e
        ttl = getattr(config, 'redis_transcription_ttl', 3600)
        segments_data = _compress_json(segments_metadata) if getattr(config, 'redis_transcription_compress', True) else json.dumps(segments_metadata)
        redis_client.setex(segments_key, ttl, segments_data)
        
        # Initialiser le compteur atomique √† 0 (pour √©viter les race conditions)
        counter_key = f"transcription:{transcription_id}:completed_count"
        # Utiliser set au lieu de setex pour s'assurer que c'est bien un entier
        redis_client.delete(counter_key)  # S'assurer qu'il n'existe pas d√©j√†
        redis_client.set(counter_key, 0)
        redis_client.expire(counter_key, 3600)  # Expire apr√®s 1h
        
        # 4. Cr√©er une t√¢che pour chaque segment
        logger.info(
            f"[{transcription_id}] üì§ DISTRIBUTED ORCHESTRATION | Step 3/4: Creating segment tasks | "
            f"Total segments: {num_segments} | "
            f"Queue: transcription | "
            f"Tasks will be distributed automatically by Celery"
        )
        segment_tasks = []
        from celery import current_app as celery_current_app
        
        for i, segment_path in enumerate(segment_paths):
            # Calculer l'offset temporel (start_time) pour ce segment
            # On va le calculer approximativement en fonction de l'index
            # Le worker de segment pourra ajuster avec la dur√©e r√©elle
            segment_task = celery_current_app.send_task(
                'transcribe_segment',
                args=[transcription_id, str(segment_path), i, num_segments],
                queue='transcription'
            )
            segment_tasks.append(segment_task.id)
            logger.info(
                f"[{transcription_id}] üì§ DISTRIBUTED ORCHESTRATION | Segment {i+1}/{num_segments} enqueued | "
                f"Task ID: {segment_task.id} | "
                f"File: {Path(segment_path).name} | "
                f"Waiting for available worker..."
            )
        
        # 5. Stocker les IDs des t√¢ches
        tasks_key = f"transcription:{transcription_id}:segment_tasks"
        redis_client.setex(tasks_key, 3600, json.dumps(segment_tasks))
        
        logger.info(
            f"[{transcription_id}] ‚úÖ DISTRIBUTED ORCHESTRATION | Step 3/4: All segment tasks created | "
            f"Total tasks: {num_segments} | "
            f"Task IDs: {', '.join(segment_tasks[:5])}{'...' if len(segment_tasks) > 5 else ''} | "
            f"Next: Workers will process segments in parallel"
        )
        
        return {
            "status": "orchestrated",
            "transcription_id": transcription_id,
            "num_segments": num_segments,
            "segment_tasks": segment_tasks
        }
        
    except Exception as e:
        logger.error(f"[{transcription_id}] ‚ùå Orchestration error: {e}", exc_info=True)
        try:
            api_client = get_api_client()
            api_client.update_transcription(transcription_id, {
                "status": "error",
                "error_message": f"Orchestration failed: {str(e)}"
            })
        except:
            pass
        raise

@celery_app.task(
    bind=True,
    name='transcribe_segment',
    max_retries=2,
    default_retry_delay=30,
    acks_late=True,
    reject_on_worker_lost=True
)
def transcribe_segment_task(self, transcription_id: str, segment_path: str, segment_index: int, total_segments: int):
    """
    Transcrit un seul segment audio.
    
    Args:
        transcription_id: ID de la transcription parente
        segment_path: Chemin vers le segment audio
        segment_index: Index du segment (0-based)
        total_segments: Nombre total de segments
    """
    logger.info(
        f"[{transcription_id}] üéØ DISTRIBUTED SEGMENT STARTED | "
        f"Segment: {segment_index+1}/{total_segments} | "
        f"Worker: {config.instance_name} | "
        f"Task ID: {self.request.id} | "
        f"File: {Path(segment_path).name}"
    )
    start_time = time.time()
    
    try:
        # R√©cup√©rer les m√©tadonn√©es depuis Redis
        redis_client = get_redis_client()
        segments_key = f"transcription:{transcription_id}:segments"
        metadata_json = redis_client.get(segments_key)
        
        if not metadata_json:
            raise ValueError(f"Metadata not found for transcription {transcription_id}")
        
        # D√©compresser si n√©cessaire
        try:
            metadata = _decompress_json(metadata_json)
        except:
            # Fallback : essayer comme JSON normal (r√©trocompatibilit√©)
            metadata = json.loads(metadata_json)
        use_vad = metadata.get('use_vad', True)
        whisper_model = metadata.get('whisper_model', 'small')
        
        logger.info(
            f"[{transcription_id}] ‚öôÔ∏è DISTRIBUTED SEGMENT | Worker {config.instance_name} processing | "
            f"Segment: {segment_index+1}/{total_segments} | "
            f"Model: {whisper_model} | VAD: {use_vad}"
        )
        
        # Transcrit le segment
        transcription_service = get_transcription_service(model_name=whisper_model)
        segment_path_obj = Path(segment_path)
        
        if not segment_path_obj.exists():
            raise FileNotFoundError(f"Segment not found: {segment_path}")
        
        text, segments_list, lang = transcription_service.transcribe_segment(
            segment_path_obj,
            use_vad=use_vad
        )
        
        processing_time = round(time.time() - start_time, 2)
        
        # Calculer l'offset temporel pour ce segment
        # On utilise la dur√©e cumul√©e des segments pr√©c√©dents
        time_offset = 0.0
        if segment_index > 0:
            # R√©cup√©rer les r√©sultats des segments pr√©c√©dents pour calculer l'offset
            for prev_idx in range(segment_index):
                prev_result_key = f"transcription:{transcription_id}:segment:{prev_idx}:result"
                prev_result_json = redis_client.get(prev_result_key)
                if prev_result_json:
                    try:
                        # D√©compresser si n√©cessaire (comme pour les m√©tadonn√©es)
                        try:
                            prev_result = _decompress_json(prev_result_json)
                        except:
                            # Fallback : essayer comme JSON normal (r√©trocompatibilit√©)
                            prev_result = json.loads(prev_result_json)
                        
                        if prev_result.get('segments'):
                            # Prendre le dernier timestamp du segment pr√©c√©dent
                            last_segment = prev_result['segments'][-1]
                            time_offset = last_segment.get('end', 0.0)
                            break  # On prend le dernier segment disponible
                    except (json.JSONDecodeError, KeyError, IndexError) as e:
                        # Si le segment pr√©c√©dent n'est pas encore disponible ou invalide, ignorer
                        logger.debug(f"[{transcription_id}] Segment {prev_idx} not yet available or invalid, skipping offset calculation: {e}")
                        continue
        
        # Ajuster les timestamps avec l'offset
        adjusted_segments = []
        for seg in segments_list:
            adjusted_segments.append({
                "start": round(seg["start"] + time_offset, 2),
                "end": round(seg["end"] + time_offset, 2),
                "text": seg["text"]
            })
        
        # Stocker le r√©sultat dans Redis
        result = {
            "segment_index": segment_index,
            "text": text,
            "segments": adjusted_segments,
            "language": lang,
            "processing_time": processing_time,
            "time_offset": time_offset
        }
        
        result_key = f"transcription:{transcription_id}:segment:{segment_index}:result"
        # Stocker avec compression si activ√©e
        ttl = getattr(config, 'redis_transcription_ttl', 3600)
        result_data = _compress_json(result) if getattr(config, 'redis_transcription_compress', True) else json.dumps(result)
        redis_client.setex(result_key, ttl, result_data)
        
        # Incr√©menter le compteur de segments compl√©t√©s de mani√®re atomique (√©vite les race conditions)
        counter_key = f"transcription:{transcription_id}:completed_count"
        completed_count = int(redis_client.incr(counter_key))  # S'assurer que c'est un entier
        redis_client.expire(counter_key, 3600)  # Expire apr√®s 1h
        
        # Mettre √† jour les m√©tadonn√©es (sans le compteur, il est g√©r√© s√©par√©ment)
        metadata['completed_segments'] = completed_count
        ttl = getattr(config, 'redis_transcription_ttl', 3600)
        metadata_data = _compress_json(metadata) if getattr(config, 'redis_transcription_compress', True) else json.dumps(metadata)
        redis_client.setex(segments_key, ttl, metadata_data)
        
        logger.info(
            f"[{transcription_id}] ‚úÖ DISTRIBUTED SEGMENT COMPLETED | "
            f"Segment: {segment_index+1}/{total_segments} | "
            f"Worker: {config.instance_name} | "
            f"Processing time: {processing_time}s | "
            f"Progress: {completed_count}/{total_segments} segments done ({100*completed_count/total_segments:.1f}%)"
        )
        
        # Si tous les segments sont termin√©s, d√©clencher l'agr√©gation
        # Utiliser une op√©ration atomique pour √©viter les d√©clenchements multiples
        if completed_count >= total_segments:
            # Utiliser un verrou Redis pour s'assurer qu'un seul worker d√©clenche l'agr√©gation
            lock_key = f"transcription:{transcription_id}:aggregation_lock"
            lock_acquired = redis_client.set(lock_key, "1", ex=300, nx=True)  # nx=True = set only if not exists
            
            if lock_acquired:
                logger.info(
                    f"[{transcription_id}] üéâ DISTRIBUTED MODE | All segments completed | "
                    f"Total: {total_segments} segments | "
                    f"All workers finished | "
                    f"Triggering aggregation... (lock acquired by {config.instance_name})"
                )
                from celery import current_app as celery_current_app
                aggregate_task = celery_current_app.send_task(
                    'aggregate_segments',
                    args=[transcription_id],
                    queue='transcription',
                    countdown=1
                )
                logger.info(
                    f"[{transcription_id}] ‚úÖ DISTRIBUTED MODE | Aggregation task enqueued | "
                    f"Task ID: {aggregate_task.id} | "
                    f"Queue: transcription | "
                    f"Next: Reassembling all segments"
                )
            else:
                logger.info(
                    f"[{transcription_id}] ‚ÑπÔ∏è DISTRIBUTED MODE | All segments completed but aggregation already triggered by another worker"
                )
        
        return {
            "status": "success",
            "segment_index": segment_index,
            "processing_time": processing_time
        }
        
    except Exception as e:
        logger.error(f"[{transcription_id}] ‚ùå Segment {segment_index+1} error: {e}", exc_info=True)
        raise

@celery_app.task(
    bind=True,
    name='aggregate_segments',
    max_retries=2,
    default_retry_delay=30,
    acks_late=True
)
def aggregate_segments_task(self, transcription_id: str):
    """
    R√©assemble les segments transcrits en un r√©sultat final.
    
    Args:
        transcription_id: ID de la transcription
    """
    logger.info(
        f"[{transcription_id}] üîó DISTRIBUTED AGGREGATION STARTED | "
        f"Worker: {config.instance_name} | "
        f"Task ID: {self.request.id} | "
        f"Will reassemble all completed segments"
    )
    start_time = time.time()
    
    try:
        redis_client = get_redis_client()
        
        # R√©cup√©rer les m√©tadonn√©es
        segments_key = f"transcription:{transcription_id}:segments"
        metadata_json = redis_client.get(segments_key)
        
        if not metadata_json:
            raise ValueError(f"Metadata not found for transcription {transcription_id}")
        
        # D√©compresser si n√©cessaire
        try:
            metadata = _decompress_json(metadata_json)
        except:
            # Fallback : essayer comme JSON normal (r√©trocompatibilit√©)
            metadata = json.loads(metadata_json)
        total_segments = metadata['total_segments']
        use_diarization = metadata.get('use_diarization', False)
        
        # R√©cup√©rer tous les r√©sultats des segments
        logger.info(
            f"[{transcription_id}] üì• DISTRIBUTED AGGREGATION | Step 1/3: Collecting segment results | "
            f"Expected segments: {total_segments}"
        )
        all_segments = []
        full_text = ""
        language_detected = None
        max_segment_time = 0.0  # Temps maximum d'un segment (car traitement en parall√®le)
        segment_processing_times = []  # Pour statistiques
        
        for i in range(total_segments):
            result_key = f"transcription:{transcription_id}:segment:{i}:result"
            result_json = redis_client.get(result_key)
            
            if not result_json:
                raise ValueError(f"Result not found for segment {i} of transcription {transcription_id}")
            
            # D√©compresser si n√©cessaire
            try:
                result = _decompress_json(result_json)
            except:
                # Fallback : essayer comme JSON normal (r√©trocompatibilit√©)
                result = json.loads(result_json)
            all_segments.extend(result['segments'])
            full_text += result['text'] + " "
            segment_time = result.get('processing_time', 0.0)
            segment_processing_times.append(segment_time)
            max_segment_time = max(max_segment_time, segment_time)  # Temps max car traitement en parall√®le
            
            if language_detected is None:
                language_detected = result.get('language')
        
        # Calculer le temps r√©el √©coul√© depuis le d√©but de l'orchestration
        orchestration_start_time = metadata.get('orchestration_start_time')
        if orchestration_start_time:
            real_elapsed_time = round(time.time() - orchestration_start_time, 2)
        else:
            # Fallback : utiliser le temps max des segments + temps d'agr√©gation
            real_elapsed_time = max_segment_time
        
        logger.info(
            f"[{transcription_id}] ‚úÖ DISTRIBUTED AGGREGATION | Step 1/3: All results collected | "
            f"Segments: {len(all_segments)} | "
            f"Max segment time: {max_segment_time:.1f}s (parallel) | "
            f"Real elapsed time: {real_elapsed_time:.1f}s"
        )
        
        # Trier les segments par timestamp (au cas o√π ils arrivent dans le d√©sordre)
        all_segments.sort(key=lambda x: x['start'])
        logger.info(
            f"[{transcription_id}] üîÑ DISTRIBUTED AGGREGATION | Step 2/3: Segments sorted by timestamp | "
            f"Total segments: {len(all_segments)}"
        )
        
        # Diarisation si demand√©e
        if use_diarization:
            logger.info(f"[{transcription_id}] üé§ Running speaker diarization on aggregated segments...")
            try:
                transcription_service = get_transcription_service(model_name=metadata.get('whisper_model', 'small'))
                if transcription_service.diarization_service and transcription_service.diarization_service.pipeline:
                    diarization_audio_path = Path(metadata['processed_path_stereo']) if metadata.get('processed_path_stereo') else Path(metadata['processed_path_mono'])
                    
                    if diarization_audio_path.exists():
                        diarization_segments = transcription_service.diarization_service.diarize(diarization_audio_path)
                        
                        if diarization_segments:
                            all_segments = transcription_service.diarization_service.assign_speakers_to_segments(
                                all_segments,
                                diarization_segments
                            )
                            logger.info(f"[{transcription_id}] ‚úÖ Diarization completed and assigned to segments")
            except Exception as e:
                logger.warning(f"[{transcription_id}] ‚ö†Ô∏è Diarization error: {e}")
        
        # Sauvegarder le r√©sultat final
        api_client = get_api_client()
        transcription = api_client.get_transcription(transcription_id)
        enrichment_requested = transcription.get('enrichment_requested', False) if transcription else False
        
        status = "transcribed" if enrichment_requested else "done"
        aggregation_time = round(time.time() - start_time, 2)
        
        # Le temps r√©el de traitement est le temps √©coul√© depuis le d√©but de l'orchestration
        # (ou le max des segments + agr√©gation si pas de timestamp de d√©but)
        if orchestration_start_time:
            total_processing_time = round(time.time() - orchestration_start_time, 2)
        else:
            # Fallback : max segment + agr√©gation
            total_processing_time = round(max_segment_time + aggregation_time, 2)
        
        api_client.update_transcription(transcription_id, {
            "status": status,
            "text": full_text.strip(),
            "segments": json.dumps(all_segments),
            "language": language_detected,
            "duration": metadata.get('original_duration', 0.0),
            "processing_time": total_processing_time,
            "segments_count": len(all_segments)
        })
        
        logger.info(
            f"[{transcription_id}] ‚úÖ DISTRIBUTED AGGREGATION | Step 3/3: Aggregation completed | "
            f"Total segments: {len(all_segments)} | "
            f"Real processing time: {total_processing_time:.1f}s (from orchestration start) | "
            f"Max segment time: {max_segment_time:.1f}s | "
            f"Aggregation time: {aggregation_time:.1f}s | "
            f"Status: {status} | "
            f"Result saved to database"
        )
        
        # Nettoyer les donn√©es Redis (utiliser pipeline pour performance)
        try:
            # Utiliser un pipeline Redis pour supprimer toutes les cl√©s en une seule op√©ration
            pipe = redis_client.pipeline()
            for i in range(total_segments):
                pipe.delete(f"transcription:{transcription_id}:segment:{i}:result")
            pipe.delete(segments_key)
            pipe.delete(f"transcription:{transcription_id}:segment_tasks")
            pipe.delete(f"transcription:{transcription_id}:completed_count")
            pipe.delete(f"transcription:{transcription_id}:aggregation_lock")
            pipe.execute()  # Ex√©cuter toutes les suppressions en une seule fois
            logger.debug(f"[{transcription_id}] üßπ Redis cleanup completed (pipeline)")
            
            # Nettoyer les fichiers temporaires
            from audio_utils import cleanup_segments
            segment_paths = [Path(p) for p in metadata.get('segment_paths', [])]
            cleanup_segments(segment_paths)
            
            if metadata.get('processed_path_mono'):
                mono_path = Path(metadata['processed_path_mono'])
                if mono_path.exists() and mono_path != Path(transcription.get('file_path', '')):
                    mono_path.unlink()
            
            if metadata.get('processed_path_stereo'):
                stereo_path = Path(metadata['processed_path_stereo'])
                if stereo_path.exists():
                    stereo_path.unlink()
        except Exception as cleanup_error:
            logger.warning(f"[{transcription_id}] ‚ö†Ô∏è Cleanup error: {cleanup_error}")
        
        # D√©clencher l'enrichissement si demand√©
        if enrichment_requested:
            try:
                from celery import current_app as celery_current_app
                enrich_task = celery_current_app.send_task(
                    'enrich_transcription',
                    args=[transcription_id],
                    queue='enrichment',
                    countdown=1
                )
                logger.info(f"[{transcription_id}] ‚úÖ Enrichment task enqueued: {enrich_task.id}")
            except Exception as enrich_error:
                logger.warning(f"[{transcription_id}] ‚ö†Ô∏è Failed to enqueue enrichment task: {enrich_error}")
        
        return {
            "status": "success",
            "transcription_id": transcription_id,
            "segments_count": len(all_segments),
            "total_processing_time": total_processing_time
        }
        
    except Exception as e:
        logger.error(f"[{transcription_id}] ‚ùå Aggregation error: {e}", exc_info=True)
        try:
            api_client = get_api_client()
            api_client.update_transcription(transcription_id, {
                "status": "error",
                "error_message": f"Aggregation failed: {str(e)}"
            })
        except:
            pass
        raise

if __name__ == "__main__":
    # ... (Le reste de votre fichier __main__ est parfait et n'a pas besoin d'√™tre modifi√©) ...
    logger.info(f"üöÄ Starting Celery worker: {config.instance_name}")
    celery_app.worker_main([
        'worker',
        f'--loglevel={config.log_level.lower()}',
        f'--concurrency={config.max_workers}',
        f'--hostname={config.instance_name}@%h'
    ])