"""
vocalyx-transcribe/transcription_service.py
Service de transcription avec Whisper (adapt√© pour worker Celery)
"""

import logging
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from faster_whisper import WhisperModel
from audio_utils import get_audio_duration, preprocess_audio, split_audio_intelligent
from diarization import DiarizationService

# Imports non utilis√©s (TimeoutError, signal, contextmanager) supprim√©s
logger = logging.getLogger(__name__)

class TranscriptionService:
    """
    Service de transcription encapsulant le mod√®le Whisper.
    Version simplifi√©e pour worker Celery (pas de pool d'ex√©cution, Celery g√®re la concurrence).
    """
    
    def __init__(self, config):
        self.config = config
        
        # Charger le mod√®le Whisper
        self._load_model()
        
        # Charger le service de diarisation (toujours initialiser, m√™me si pas activ√© globalement)
        # Cela permet d'utiliser la diarisation √† la demande par transcription
        self.diarization_service = None
        try:
            self.diarization_service = DiarizationService(config)
            if self.diarization_service.pipeline is None:
                logger.info("‚ÑπÔ∏è Diarization service initialized but model not available (will be skipped if requested)")
            else:
                logger.info("‚úÖ Diarization service initialized and ready")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to initialize diarization service: {e} (will be skipped if requested)")
            self.diarization_service = None
    
    def _load_model(self):
        """Charge le mod√®le Whisper"""
        logger.info(f"üöÄ Loading Whisper model: {self.config.model}")
        logger.info(f"üìä Device: {self.config.device} | Compute: {self.config.compute_type}")
        
        self.model = WhisperModel(
            self.config.model,
            device=self.config.device,
            compute_type=self.config.compute_type,
            cpu_threads=self.config.cpu_threads
        )
        
        logger.info(f"‚úÖ Whisper model loaded successfully")
        logger.info(f"‚öôÔ∏è VAD: {self.config.vad_enabled} | Beam size: {self.config.beam_size}")
        
    def transcribe_segment(self, file_path: Path, use_vad: bool = True, retry_without_vad: bool = True) -> Tuple[str, List[Dict], str]:
        """
        Transcrit un segment audio avec consommation progressive du g√©n√©rateur.
        """
        if self.model is None:
            raise RuntimeError("Whisper model not loaded")
        
        segments_list = []
        text_full = ""
        segments_list_raw = [] # Initialiser ici
        info = None # Initialiser info
        
        logger.info(f"üéØ Starting Whisper transcription (VAD: {use_vad})...")
        
        try:
            vad_params = None
            if use_vad:
                # Utiliser les param√®tres VAD de la config (plus coh√©rent)
                vad_params = dict(
                    threshold=self.config.vad_threshold,
                    min_speech_duration_ms=self.config.vad_min_speech_duration_ms,
                    min_silence_duration_ms=self.config.vad_min_silence_duration_ms,
                    speech_pad_ms=self.config.vad_speech_pad_ms
                )
            
            segments, info = self.model.transcribe(
                str(file_path),
                language=self.config.language or None,
                task="transcribe",
                beam_size=self.config.beam_size,
                best_of=self.config.beam_size,
                temperature=self.config.temperature,
                vad_filter=use_vad,
                vad_parameters=vad_params,
                word_timestamps=False,
                condition_on_previous_text=False,
            )
            
            logger.info(f"üéØ Whisper inference completed, consuming generator...")
            
            # --- MODIFICATION ---
            # Remplacer la boucle progressive par une consommation directe.
            # Le "lazy loading" dans worker.py a corrig√© le blocage.
            start_consume_time = time.time()
            segments_list_raw = list(segments) # Force l'√©valuation compl√®te
            consume_time = time.time() - start_consume_time
            logger.info(f"‚úÖ Generator consumed, got {len(segments_list_raw)} segments in {consume_time:.1f}s")
            # --- FIN MODIFICATION ---
            
        except Exception as e:
            # G√©rer les erreurs de transcription ou de consommation
            logger.error(f"‚ùå Error during transcription/consumption: {e}", exc_info=True)
            
            if use_vad and retry_without_vad:
                logger.warning(f"‚ö†Ô∏è Retrying WITHOUT VAD...")
                return self.transcribe_segment(file_path, use_vad=False, retry_without_vad=False)
            else:
                raise Exception(f"Transcription failed: {e}")
        
        # S'assurer que 'info' a √©t√© d√©fini
        if info is None:
            logger.error("‚ùå 'info' n'a pas √©t√© retourn√© par model.transcribe(), impossible de d√©tecter la langue.")
            raise Exception("Transcription failed: 'info' object is None")

        # Convertir les segments en dictionnaires
        logger.info(f"üìù Converting {len(segments_list_raw)} segments to dict...")
        
        for i, seg in enumerate(segments_list_raw):
            try:
                segments_list.append({
                    "start": round(seg.start, 2),
                    "end": round(seg.end, 2),
                    "text": seg.text.strip()
                })
                text_full += seg.text.strip() + " "
                
                if (i + 1) % 10 == 0:
                    logger.info(f"üìù Processed {i + 1}/{len(segments_list_raw)} segments")
                    
            except Exception as e:
                logger.error(f"‚ùå Error processing segment {i}: {e}")
                continue
        
        logger.info(f"‚úÖ All {len(segments_list)} segments processed")
        
        return text_full.strip(), segments_list, info.language
    
    def transcribe(self, file_path: str, use_vad: bool = True, use_diarization: bool = False) -> Dict:
        """
        Transcrit un fichier audio (point d'entr√©e principal).
        
        Args:
            file_path: Chemin vers le fichier audio
            use_vad: Utiliser la d√©tection de voix
            use_diarization: Activer la diarisation des locuteurs
            
        Returns:
            dict: R√©sultats de la transcription
        """
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"Audio file not found: {file_path}")
        
        logger.info(f"üìÅ Processing file: {file_path.name} | VAD requested: {use_vad}")
        
        segment_paths = []
        processed_path = None
        
        try:
            start_time = time.time()
            
            # 1. Obtenir la dur√©e r√©elle de l'audio
            original_duration = get_audio_duration(file_path)
            logger.info(f"üìè Audio duration: {original_duration}s")
            
            # 2. Pr√©-traitement audio (normalisation, conversion mono 16kHz)
            processed_path = preprocess_audio(file_path)
            logger.info(f"‚ú® Audio preprocessed")
            
            # 3. D√©coupe intelligente (si n√©cessaire)
            segment_paths = split_audio_intelligent(
                processed_path,
                use_vad=use_vad
            )
            logger.info(f"üî™ Created {len(segment_paths)} segment(s)")
            
            # 4. Transcription
            full_text = ""
            full_segments = []
            language_detected = None
            time_offset = 0.0
            
            for i, segment_path in enumerate(segment_paths):
                logger.info(f"üé§ Transcribing segment {i+1}/{len(segment_paths)}...")
                
                text, segments_list, lang = self.transcribe_segment(segment_path, use_vad=use_vad)
                
                # Ajuster les timestamps avec l'offset
                for seg in segments_list:
                    seg["start"] = round(seg["start"] + time_offset, 2)
                    seg["end"] = round(seg["end"] + time_offset, 2)
                    full_segments.append(seg)
                
                # Mettre √† jour l'offset pour le prochain segment
                if full_segments:
                    time_offset = full_segments[-1]["end"]
                
                full_text += text + " "
                
                if not language_detected:
                    language_detected = lang
            
            # 5. Diarisation (si activ√©e pour cette transcription)
            if use_diarization:
                if self.diarization_service and self.diarization_service.pipeline:
                    logger.info("üé§ Running speaker diarization...")
                    try:
                        # Utiliser le fichier audio original pour la diarisation
                        diarization_segments = self.diarization_service.diarize(file_path)
                        
                        if diarization_segments:
                            # Assigner les locuteurs aux segments de transcription
                            full_segments = self.diarization_service.assign_speakers_to_segments(
                                full_segments,
                                diarization_segments
                            )
                            logger.info("‚úÖ Speaker diarization completed and assigned to segments")
                        else:
                            logger.warning("‚ö†Ô∏è Diarization returned no segments")
                    except Exception as e:
                        logger.error(f"‚ùå Error during diarization: {e}", exc_info=True)
                        # Continuer sans diarisation en cas d'erreur
                else:
                    logger.warning("‚ö†Ô∏è Diarization requested but service not available (check model configuration)")
            
            processing_time = round(time.time() - start_time, 2)
            speed_ratio = round(original_duration / processing_time, 2) if processing_time > 0 else 0
            
            logger.info(
                f"‚úÖ Transcription completed | "
                f"Segments: {len(full_segments)} | "
                f"Speed: {speed_ratio}x realtime"
            )
            
            return {
                "text": full_text.strip(),
                "segments": full_segments,
                "language": language_detected,
                "duration": original_duration,
                "processing_time": processing_time,
                "segments_count": len(full_segments)
            }
            
        finally:
            # Nettoyage des fichiers temporaires
            try:
                if processed_path and processed_path != file_path and processed_path.exists():
                    processed_path.unlink()
                
                for seg_path in segment_paths:
                    if seg_path.exists():
                        seg_path.unlink()
                
                logger.debug("üßπ Temporary files cleaned")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Cleanup error: {e}")
