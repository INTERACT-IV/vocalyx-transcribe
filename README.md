# vocalyx-transcribe

Worker Celery pour la transcription audio avec Faster-Whisper.

## ğŸ¯ RÃ´le

- **Consommateur** des tÃ¢ches Celery depuis la queue Redis
- ExÃ©cution des transcriptions avec Faster-Whisper
- Communication avec `vocalyx-api` via HTTP pour rÃ©cupÃ©rer et mettre Ã  jour les transcriptions
- Scalable horizontalement (plusieurs workers possibles)

## ğŸ—ï¸ Architecture

```
vocalyx-transcribe/
â”œâ”€â”€ transcribe/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ audio_utils.py         # Utilitaires audio (VAD, dÃ©coupe)
â”œâ”€â”€ logs/                       # RÃ©pertoire des logs
â”œâ”€â”€ models/                     # ModÃ¨les Whisper (peut Ãªtre montÃ© en volume)
â”œâ”€â”€ shared_uploads/             # Uploads partagÃ©s avec l'API
â”œâ”€â”€ worker.py                   # Point d'entrÃ©e Celery Worker
â”œâ”€â”€ api_client.py               # Client HTTP vers vocalyx-api
â”œâ”€â”€ transcription_service.py    # Service de transcription Whisper
â”œâ”€â”€ config.py                   # Configuration
â”œâ”€â”€ logging_config.py           # Configuration du logging
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ config.ini
```

## ğŸš€ Installation

### PrÃ©requis

- Python 3.10+
- Redis (pour Celery)
- vocalyx-api en cours d'exÃ©cution
- FFmpeg (pour le traitement audio)

### Installation locale

```bash
# Cloner le dÃ©pÃ´t
git clone <repository>
cd vocalyx-transcribe

# CrÃ©er un environnement virtuel
python3.10 -m venv venv
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# TÃ©lÃ©charger le modÃ¨le Whisper (si pas dÃ©jÃ  fait)
# Il sera tÃ©lÃ©chargÃ© automatiquement au premier lancement

# Configurer
cp config.ini config.local.ini
# Ã‰diter config.local.ini

# Lancer le worker
python worker.py

# OU avec Celery directement
celery -A worker.celery_app worker --loglevel=info --concurrency=2
```

## ğŸ³ Docker

```bash
# Build
docker build -t vocalyx-transcribe .

# Run
docker run \
  -e CELERY_BROKER_URL="redis://redis:6379/0" \
  -e VOCALYX_API_URL="http://vocalyx-api:8000" \
  -v $(pwd)/shared_uploads:/app/shared_uploads \
  -v $(pwd)/models:/app/models \
  vocalyx-transcribe
```

## âš™ï¸ Configuration

### ParamÃ¨tres Principaux

#### Model Whisper
```ini
[WHISPER]
model = ./models/openai-whisper-small  # tiny, base, small, medium, large-v3
device = cpu                            # cpu, cuda
compute_type = int8                     # int8, float16, float32
language = fr                           # fr, en, es, etc.
```

#### Performance
```ini
[PERFORMANCE]
max_workers = 2          # Concurrence Celery
vad_enabled = true       # Voice Activity Detection
beam_size = 5            # QualitÃ© du dÃ©codage
```

#### API
```ini
[API]
url = http://localhost:8000    # URL de vocalyx-api
```

#### Celery
```ini
[CELERY]
broker_url = redis://localhost:6379/0
result_backend = redis://localhost:6379/0
```

## ğŸ”„ Flux de Travail

```
1. Worker dÃ©marre et se connecte Ã  Redis
2. Worker attend une tÃ¢che "transcribe_audio"
3. TÃ¢che reÃ§ue avec transcription_id
4. Worker â†’ API: GET /api/transcriptions/{id} (rÃ©cupÃ©rer infos)
5. Worker â†’ API: PATCH /api/transcriptions/{id} (status=processing)
6. Worker exÃ©cute la transcription Whisper
7. Worker â†’ API: PATCH /api/transcriptions/{id} (rÃ©sultats + status=done)
8. Worker attend la prochaine tÃ¢che
```

## ğŸ“Š Monitoring

### Logs
```bash
# Logs du worker
tail -f logs/vocalyx-transcribe.log
```

### Celery Flower (optionnel)
```bash
# DÃ©marrer Flower pour monitoring web
celery -A worker.celery_app flower --port=5555

# AccÃ©der: http://localhost:5555
```

### Commandes Celery Utiles
```bash
# Voir les workers actifs
celery -A worker.celery_app inspect active

# Voir les tÃ¢ches en attente
celery -A worker.celery_app inspect reserved

# Statistiques
celery -A worker.celery_app inspect stats

# ArrÃªter tous les workers
celery -A worker.celery_app control shutdown
```

## ğŸ”§ ScalabilitÃ©

### Lancer plusieurs workers

```bash
# Worker 1
INSTANCE_NAME=worker-01 python worker.py

# Worker 2 (autre terminal)
INSTANCE_NAME=worker-02 python worker.py

# Worker 3 (autre terminal)
INSTANCE_NAME=worker-03 python worker.py
```

Ou avec Docker Compose (voir docker-compose.yml dans la racine).

### StratÃ©gies de ScalabilitÃ©

1. **Horizontal** : Ajouter plus de workers
2. **Vertical** : Augmenter `max_workers` (concurrence Celery)
3. **GPU** : Utiliser `device=cuda` pour des transcriptions plus rapides

## ğŸš¨ Gestion des Erreurs

Le worker gÃ¨re automatiquement :
- **Retry** : 3 tentatives avec 60s entre chaque
- **Crash** : Celery re-enqueue automatiquement la tÃ¢che
- **API indisponible** : Le worker continue mais logge l'erreur
- **Fichier manquant** : Marque la transcription en erreur

## ğŸ”’ SÃ©curitÃ©

### Communication avec l'API

Le worker utilise une clÃ© interne (`X-Internal-Key`) pour communiquer avec vocalyx-api.

```ini
[SECURITY]
internal_api_key = SECRET_KEY_HERE
```

**âš ï¸ Cette clÃ© DOIT Ãªtre identique Ã  celle configurÃ©e dans vocalyx-api.**

## ğŸ“ Changelog

### Version 1.0.0
- Architecture microservices (worker Celery)
- Communication HTTP avec vocalyx-api
- Plus d'accÃ¨s direct Ã  la base de donnÃ©es
- Support multi-workers natif

## ğŸ“„ Licence

PropriÃ©taire - Guilhem RICHARD